{
  "cve": {
    "data_type": "CVE",
    "data_format": "MITRE",
    "data_version": "4.0",
    "CVE_data_meta": {
      "ID": "CVE-2024-10954",
      "ASSIGNER": "security@huntr.dev"
    },
    "problemtype": {
      "problemtype_data": [
        {
          "description": [
            {
              "lang": "en",
              "value": "CWE-77"
            }
          ]
        }
      ]
    },
    "references": {
      "reference_data": [
        {
          "url": "https://huntr.com/bounties/72d034e3-6ca2-495d-98a7-ac9565588c09",
          "name": "https://huntr.com/bounties/72d034e3-6ca2-495d-98a7-ac9565588c09",
          "refsource": "",
          "tags": []
        }
      ]
    },
    "description": {
      "description_data": [
        {
          "lang": "en",
          "value": "In the `manim` plugin of binary-husky/gpt_academic, versions prior to the fix, a vulnerability exists due to improper handling of user-provided prompts. The root cause is the execution of untrusted code generated by the LLM without a proper sandbox. This allows an attacker to perform remote code execution (RCE) on the app backend server by injecting malicious code through the prompt."
        }
      ]
    }
  },
  "configurations": {
    "CVE_data_version": "4.0",
    "nodes": []
  },
  "impact": {},
  "publishedDate": "2025-03-20T10:15Z",
  "lastModifiedDate": "2025-03-20T10:15Z"
}